{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8bd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def CreateModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape)\n",
    "    x = Conv2D(18, (3, 3), name=\"conv2d_1\")(x)\n",
    "    x = Activation(\"relu\", name=\"act_1\")(x)\n",
    "    x = Conv2D(32, (3, 3), name=\"conv2d_2\")(x)\n",
    "    x = Activation(\"relu\", name=\"act_2\")(x)\n",
    "    x = Flatten(name=\"flatten\")(x)\n",
    "    x = Dense(nb_classes, name=\"dense\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(x_train.shape + (1,)).astype(\"float32\")\n",
    "    x_test = x_test.reshape(x_test.shape + (1,)).astype(\"float32\")\n",
    "\n",
    "    x_train /= 256.0\n",
    "    x_test /= 256.0\n",
    "\n",
    "    x_mean = np.mean(x_train, axis=0)\n",
    "\n",
    "    x_train -= x_mean\n",
    "    x_test -= x_mean\n",
    "\n",
    "    nb_classes = np.max(y_train)+1\n",
    "    y_train = to_categorical(y_train, nb_classes)\n",
    "    y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b744cdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 0.2133 - accuracy: 0.9393 - val_loss: 0.0760 - val_accuracy: 0.9760\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0666 - accuracy: 0.9804 - val_loss: 0.0586 - val_accuracy: 0.9813\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 1s 1ms/step - loss: 0.0465 - accuracy: 0.9858 - val_loss: 0.0523 - val_accuracy: 0.9838\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 18)        180       \n",
      "                                                                 \n",
      " act_1 (Activation)          (None, 26, 26, 18)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 32)        5216      \n",
      "                                                                 \n",
      " act_2 (Activation)          (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                184330    \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189,726\n",
      "Trainable params: 189,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = get_data()\n",
    "model = CreateModel(x_train.shape[1:], y_train.shape[-1])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=128, validation_data=(x_test, y_test), verbose=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3886f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras import *\n",
    "\n",
    "def CreateQModel(shape, nb_classes):\n",
    "    x = x_in = Input(shape)\n",
    "    x = QConv2D(18, (3, 3),\n",
    "        kernel_quantizer=\"stochastic_ternary\", \n",
    "        bias_quantizer=\"quantized_po2(4)\",\n",
    "        name=\"conv2d_1\")(x)\n",
    "    x = QActivation(\"quantized_relu(2)\", name=\"act_1\")(x)\n",
    "    x = QConv2D(32, (3, 3), \n",
    "        kernel_quantizer=\"stochastic_ternary\", \n",
    "        bias_quantizer=\"quantized_po2(4)\",\n",
    "        name=\"conv2d_2\")(x)\n",
    "    x = QActivation(\"quantized_relu(2)\", name=\"act_2\")(x)\n",
    "    x = Flatten(name=\"flatten\")(x)\n",
    "    x = QDense(nb_classes,\n",
    "        kernel_quantizer=\"quantized_bits(3,0,1)\",\n",
    "        bias_quantizer=\"quantized_bits(3)\",\n",
    "        name=\"dense\")(x)\n",
    "    x = Activation(\"softmax\", name=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdbe2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chmoser/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "qmodel = CreateQModel(x_train.shape[1:], y_train.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a00fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 4ms/step - loss: 0.2476 - accuracy: 0.9290 - val_loss: 0.1094 - val_accuracy: 0.9682\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0908 - accuracy: 0.9736 - val_loss: 0.0712 - val_accuracy: 0.9772\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0650 - accuracy: 0.9804 - val_loss: 0.0616 - val_accuracy: 0.9800\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0544 - accuracy: 0.9837 - val_loss: 0.0615 - val_accuracy: 0.9795\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.0551 - val_accuracy: 0.9819\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.0567 - val_accuracy: 0.9804\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.0615 - val_accuracy: 0.9807\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.0540 - val_accuracy: 0.9814\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 0.0513 - val_accuracy: 0.9824\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0569 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce54076d90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "qmodel.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(0.0005),\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "qmodel.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b83dee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_2, layer type: Input\n",
      "Layer name: conv2d_1, layer type: QConv2D\n",
      "Layer name: act_1, layer type: QActivation\n",
      "Layer name: conv2d_2, layer type: QConv2D\n",
      "Layer name: act_2, layer type: QActivation\n",
      "Layer name: dense, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "-----------------------------------\n",
      "Configuration\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'plotting' has no attribute 'print_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfiguration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mplotting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_dict\u001b[49m(config)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'plotting' has no attribute 'print_dict'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 648x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config = hls4ml.utils.config.config_from_keras_model(qmodel, granularity='model')\n",
    "plt.figure(figsize=(9,9))\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "# plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8fc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model_1/hls4ml_prj',\n",
    "                                                       part='xc7a100t_ftg256.bsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "576998e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "Collecting plotting\n",
      "  Downloading plotting-0.0.7-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/chmoser/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (296 kB)\n",
      "Requirement already satisfied: numpy>=1.19 in /home/chmoser/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/chmoser/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/chmoser/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (22.0)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Using cached pandas-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "Requirement already satisfied: six>=1.5 in /home/chmoser/miniconda3/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chmoser/miniconda3/envs/tf/lib/python3.9/site-packages (from pandas->plotting) (2022.7)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib, seaborn, plotting\n",
      "Successfully installed contourpy-1.0.6 cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.6.2 pandas-1.5.2 pillow-9.4.0 plotting-0.0.7 seaborn-0.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9fca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
