{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c90720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "BasicInputBinarizer-1            [-1, 3, 32, 32]               0\n",
      "XNORWeightBinarizer-2              [-1, 3, 7, 7]               0\n",
      "BasicScaleBinarizer-3           [-1, 64, 16, 16]               0\n",
      "            Conv2d-4           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-5           [-1, 64, 16, 16]             128\n",
      "              ReLU-6           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-7             [-1, 64, 8, 8]               0\n",
      "BasicInputBinarizer-8             [-1, 64, 8, 8]               0\n",
      "XNORWeightBinarizer-9             [-1, 64, 3, 3]               0\n",
      "BasicScaleBinarizer-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-12             [-1, 64, 8, 8]             128\n",
      "             ReLU-13             [-1, 64, 8, 8]               0\n",
      "BasicInputBinarizer-14             [-1, 64, 8, 8]               0\n",
      "XNORWeightBinarizer-15             [-1, 64, 3, 3]               0\n",
      "BasicScaleBinarizer-16             [-1, 64, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-20             [-1, 64, 8, 8]               0\n",
      "BasicInputBinarizer-21             [-1, 64, 8, 8]               0\n",
      "XNORWeightBinarizer-22             [-1, 64, 3, 3]               0\n",
      "BasicScaleBinarizer-23             [-1, 64, 8, 8]               0\n",
      "           Conv2d-24             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-25             [-1, 64, 8, 8]             128\n",
      "             ReLU-26             [-1, 64, 8, 8]               0\n",
      "BasicInputBinarizer-27             [-1, 64, 8, 8]               0\n",
      "XNORWeightBinarizer-28             [-1, 64, 3, 3]               0\n",
      "BasicScaleBinarizer-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-33             [-1, 64, 8, 8]               0\n",
      "BasicInputBinarizer-34             [-1, 64, 8, 8]               0\n",
      "XNORWeightBinarizer-35             [-1, 64, 3, 3]               0\n",
      "BasicScaleBinarizer-36            [-1, 128, 4, 4]               0\n",
      "           Conv2d-37            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-38            [-1, 128, 4, 4]             256\n",
      "             ReLU-39            [-1, 128, 4, 4]               0\n",
      "BasicInputBinarizer-40            [-1, 128, 4, 4]               0\n",
      "XNORWeightBinarizer-41            [-1, 128, 3, 3]               0\n",
      "BasicScaleBinarizer-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-44            [-1, 128, 4, 4]             256\n",
      "BasicInputBinarizer-45             [-1, 64, 8, 8]               0\n",
      "XNORWeightBinarizer-46             [-1, 64, 1, 1]               0\n",
      "BasicScaleBinarizer-47            [-1, 128, 4, 4]               0\n",
      "           Conv2d-48            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-49            [-1, 128, 4, 4]             256\n",
      "             ReLU-50            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-51            [-1, 128, 4, 4]               0\n",
      "BasicInputBinarizer-52            [-1, 128, 4, 4]               0\n",
      "XNORWeightBinarizer-53            [-1, 128, 3, 3]               0\n",
      "BasicScaleBinarizer-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-56            [-1, 128, 4, 4]             256\n",
      "             ReLU-57            [-1, 128, 4, 4]               0\n",
      "BasicInputBinarizer-58            [-1, 128, 4, 4]               0\n",
      "XNORWeightBinarizer-59            [-1, 128, 3, 3]               0\n",
      "BasicScaleBinarizer-60            [-1, 128, 4, 4]               0\n",
      "           Conv2d-61            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-62            [-1, 128, 4, 4]             256\n",
      "             ReLU-63            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-64            [-1, 128, 4, 4]               0\n",
      "BasicInputBinarizer-65            [-1, 128, 4, 4]               0\n",
      "XNORWeightBinarizer-66            [-1, 128, 3, 3]               0\n",
      "BasicScaleBinarizer-67            [-1, 256, 2, 2]               0\n",
      "           Conv2d-68            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-69            [-1, 256, 2, 2]             512\n",
      "             ReLU-70            [-1, 256, 2, 2]               0\n",
      "BasicInputBinarizer-71            [-1, 256, 2, 2]               0\n",
      "XNORWeightBinarizer-72            [-1, 256, 3, 3]               0\n",
      "BasicScaleBinarizer-73            [-1, 256, 2, 2]               0\n",
      "           Conv2d-74            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-75            [-1, 256, 2, 2]             512\n",
      "BasicInputBinarizer-76            [-1, 128, 4, 4]               0\n",
      "XNORWeightBinarizer-77            [-1, 128, 1, 1]               0\n",
      "BasicScaleBinarizer-78            [-1, 256, 2, 2]               0\n",
      "           Conv2d-79            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-80            [-1, 256, 2, 2]             512\n",
      "             ReLU-81            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-82            [-1, 256, 2, 2]               0\n",
      "BasicInputBinarizer-83            [-1, 256, 2, 2]               0\n",
      "XNORWeightBinarizer-84            [-1, 256, 3, 3]               0\n",
      "BasicScaleBinarizer-85            [-1, 256, 2, 2]               0\n",
      "           Conv2d-86            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 2, 2]             512\n",
      "             ReLU-88            [-1, 256, 2, 2]               0\n",
      "BasicInputBinarizer-89            [-1, 256, 2, 2]               0\n",
      "XNORWeightBinarizer-90            [-1, 256, 3, 3]               0\n",
      "BasicScaleBinarizer-91            [-1, 256, 2, 2]               0\n",
      "           Conv2d-92            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-93            [-1, 256, 2, 2]             512\n",
      "             ReLU-94            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-95            [-1, 256, 2, 2]               0\n",
      "BasicInputBinarizer-96            [-1, 256, 2, 2]               0\n",
      "XNORWeightBinarizer-97            [-1, 256, 3, 3]               0\n",
      "BasicScaleBinarizer-98            [-1, 512, 1, 1]               0\n",
      "           Conv2d-99            [-1, 512, 1, 1]       1,179,648\n",
      "     BatchNorm2d-100            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-101            [-1, 512, 1, 1]               0\n",
      "BasicInputBinarizer-102            [-1, 512, 1, 1]               0\n",
      "XNORWeightBinarizer-103            [-1, 512, 3, 3]               0\n",
      "BasicScaleBinarizer-104            [-1, 512, 1, 1]               0\n",
      "          Conv2d-105            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-106            [-1, 512, 1, 1]           1,024\n",
      "BasicInputBinarizer-107            [-1, 256, 2, 2]               0\n",
      "XNORWeightBinarizer-108            [-1, 256, 1, 1]               0\n",
      "BasicScaleBinarizer-109            [-1, 512, 1, 1]               0\n",
      "          Conv2d-110            [-1, 512, 1, 1]         131,072\n",
      "     BatchNorm2d-111            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-112            [-1, 512, 1, 1]               0\n",
      "      BasicBlock-113            [-1, 512, 1, 1]               0\n",
      "BasicInputBinarizer-114            [-1, 512, 1, 1]               0\n",
      "XNORWeightBinarizer-115            [-1, 512, 3, 3]               0\n",
      "BasicScaleBinarizer-116            [-1, 512, 1, 1]               0\n",
      "          Conv2d-117            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-118            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-119            [-1, 512, 1, 1]               0\n",
      "BasicInputBinarizer-120            [-1, 512, 1, 1]               0\n",
      "XNORWeightBinarizer-121            [-1, 512, 3, 3]               0\n",
      "BasicScaleBinarizer-122            [-1, 512, 1, 1]               0\n",
      "          Conv2d-123            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-124            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-125            [-1, 512, 1, 1]               0\n",
      "      BasicBlock-126            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-127            [-1, 512, 1, 1]               0\n",
      "BasicInputBinarizer-128                  [-1, 512]               0\n",
      "XNORWeightBinarizer-129                  [-1, 512]               0\n",
      "BasicScaleBinarizer-130                 [-1, 1000]               0\n",
      "          Linear-131                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.27\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 46.88\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "from bnn import BConfig, prepare_binary_model\n",
    "# Import a few examples of quantizers\n",
    "from bnn.ops import BasicInputBinarizer, BasicScaleBinarizer, XNORWeightBinarizer\n",
    "\n",
    "model = models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "bconfig = BConfig(\n",
    "    activation_pre_process = BasicInputBinarizer,\n",
    "    activation_post_process = BasicScaleBinarizer,\n",
    "    # optionally, one can pass certain custom variables\n",
    "    weight_pre_process = XNORWeightBinarizer.with_args(center_weights=True)\n",
    ")\n",
    "bmodel = prepare_binary_model(model, bconfig)\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(bmodel, (3, 32, 32), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e11538",
   "metadata": {},
   "outputs": [
    {
     "ename": "TraceError",
     "evalue": "symbolically traced variables cannot be used as inputs to control flow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraceError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m inp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m all_ops, all_data \u001b[38;5;241m=\u001b[39m \u001b[43mcount_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m flops, bops \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op_name, ops_count \u001b[38;5;129;01min\u001b[39;00m all_data\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pthflops/__init__.py:14\u001b[0m, in \u001b[0;36mcount_ops\u001b[0;34m(model, input, mode, custom_ops, ignore_layers, print_readable, verbose, *args)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_ops\u001b[39m(model, \u001b[38;5;28minput\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfx\u001b[39m\u001b[38;5;124m'\u001b[39m, custom_ops\u001b[38;5;241m=\u001b[39m{}, ignore_layers\u001b[38;5;241m=\u001b[39m[], print_readable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m==\u001b[39m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_jit:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcount_ops_fx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_ops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_ops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprint_readable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_readable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m==\u001b[39m mode \u001b[38;5;129;01mor\u001b[39;00m force_jit:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m force_jit:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pthflops/ops_fx.py:254\u001b[0m, in \u001b[0;36mcount_ops_fx\u001b[0;34m(model, input, custom_ops, ignore_layers, print_readable, verbose, *args)\u001b[0m\n\u001b[1;32m    251\u001b[0m model_status \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    252\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 254\u001b[0m tracer \u001b[38;5;241m=\u001b[39m \u001b[43mProfilingInterpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_ops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_ops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m tracer\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    257\u001b[0m ops \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pthflops/ops_fx.py:183\u001b[0m, in \u001b[0;36mProfilingInterpreter.__init__\u001b[0;34m(self, mod, custom_ops)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mod: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, custom_ops: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}):\n\u001b[0;32m--> 183\u001b[0m     gm \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymbolic_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(gm)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_ops \u001b[38;5;241m=\u001b[39m custom_ops\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py:1070\u001b[0m, in \u001b[0;36msymbolic_trace\u001b[0;34m(root, concrete_args)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03mSymbolic tracing API\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03m    GraphModule: a Module created from the recorded operations from ``root``.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m tracer \u001b[38;5;241m=\u001b[39m Tracer()\n\u001b[0;32m-> 1070\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcrete_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1072\u001b[0m     root\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(root, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;28;01melse\u001b[39;00m root\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m   1073\u001b[0m )\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GraphModule(tracer\u001b[38;5;241m.\u001b[39mroot, graph, name)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py:739\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_search:\n\u001b[1;32m    733\u001b[0m             _autowrap_check(\n\u001b[1;32m    734\u001b[0m                 patcher, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    735\u001b[0m             )\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_node(\n\u001b[1;32m    737\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    738\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 739\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_arg(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m),),\n\u001b[1;32m    740\u001b[0m             {},\n\u001b[1;32m    741\u001b[0m             type_expr\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    742\u001b[0m         )\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py:717\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _orig_module_call(mod, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    712\u001b[0m _autowrap_check(\n\u001b[1;32m    713\u001b[0m     patcher,\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(mod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, mod), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__globals__\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids,\n\u001b[1;32m    716\u001b[0m )\n\u001b[0;32m--> 717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py:434\u001b[0m, in \u001b[0;36mTracer.call_module\u001b[0;34m(self, m, forward, args, kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m module_qualified_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_of_module(m)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf_module(m, module_qualified_name):\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, module_qualified_name, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py:710\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_orig_module_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/bnn/layers/conv.py:92\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     91\u001b[0m     input_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_pre_process(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m     input_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(input_proc, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_pre_process\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_post_process(\n\u001b[1;32m     95\u001b[0m         input_proc,\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m     97\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py:717\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _orig_module_call(mod, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    712\u001b[0m _autowrap_check(\n\u001b[1;32m    713\u001b[0m     patcher,\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(mod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, mod), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__globals__\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids,\n\u001b[1;32m    716\u001b[0m )\n\u001b[0;32m--> 717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py:434\u001b[0m, in \u001b[0;36mTracer.call_module\u001b[0;34m(self, m, forward, args, kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m module_qualified_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_of_module(m)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf_module(m, module_qualified_name):\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, module_qualified_name, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/_symbolic_trace.py:710\u001b[0m, in \u001b[0;36mTracer.trace.<locals>.module_call_wrapper.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_orig_module_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/bnn/ops.py:135\u001b[0m, in \u001b[0;36mXNORWeightBinarizer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    132\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msub(mean)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_alpha:\n\u001b[0;32m--> 135\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_alpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     x \u001b[38;5;241m=\u001b[39m SignActivation\u001b[38;5;241m.\u001b[39mapply(x)\u001b[38;5;241m.\u001b[39mmul_(alpha\u001b[38;5;241m.\u001b[39mexpand_as(x))\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/bnn/ops.py:118\u001b[0m, in \u001b[0;36mXNORWeightBinarizer._compute_alpha\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_alpha\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    117\u001b[0m     n \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnelement()\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    119\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msum([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m], keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdiv_(n)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/proxy.py:298\u001b[0m, in \u001b[0;36mProxy.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mcreate_proxy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m'\u001b[39m, assert_fn, (\u001b[38;5;28mself\u001b[39m,), {})\n\u001b[1;32m    296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/torch/fx/proxy.py:174\u001b[0m, in \u001b[0;36mTracerBase.to_bool\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_bool\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124;03m\"\"\"Called when a proxy object is being converted to a boolean, such as\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    when used in control flow.  Normally we don't know what to do because\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    we don't know the value of the proxy, but a custom tracer can attach more\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m    information to the graph node using create_node and can choose to return a value.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraceError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbolically traced variables cannot be used as inputs to control flow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTraceError\u001b[0m: symbolically traced variables cannot be used as inputs to control flow"
     ]
    }
   ],
   "source": [
    "from pthflops import count_ops\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else \"cpu\"\n",
    "inp = torch.rand(1, 3, 224, 224).to(device)\n",
    "\n",
    "all_ops, all_data = count_ops(bmodel, inp, ignore_layers=['conv1'])\n",
    "flops, bops = 0, 0\n",
    "for op_name, ops_count in all_data.items():\n",
    "    if 'Conv2d' in op_names and 'onnx::' not in op_name:\n",
    "        bops += ops_count\n",
    "    else:\n",
    "        flops += ops_count\n",
    "        \n",
    "print('Total number of FLOPs: {}', flops)\n",
    "print('Total number of BOPs: {}', bops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15230f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ba06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
