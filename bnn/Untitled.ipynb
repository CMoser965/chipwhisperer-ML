{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8bd566",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in first_conv2d. Consider increasing the input size. Received input shape [None, 1, 28, 28] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m x_in \u001b[38;5;241m=\u001b[39m Input((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mQConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstochastic_ternary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mternary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirst_conv2d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m QActivation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantized_relu(3)\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[1;32m      9\u001b[0m x \u001b[38;5;241m=\u001b[39m QSeparableConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     10\u001b[0m         depthwise_quantizer\u001b[38;5;241m=\u001b[39mquantized_bits(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     11\u001b[0m         pointwise_quantizer\u001b[38;5;241m=\u001b[39mquantized_bits(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     12\u001b[0m         bias_quantizer\u001b[38;5;241m=\u001b[39mquantized_bits(\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     13\u001b[0m         depthwise_activation\u001b[38;5;241m=\u001b[39mquantized_tanh(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py:347\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[1;32m    341\u001b[0m             input_shape[:batch_rank]\n\u001b[1;32m    342\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters]\n\u001b[1;32m    343\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :])\n\u001b[1;32m    344\u001b[0m         )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    354\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in first_conv2d. Consider increasing the input size. Received input shape [None, 1, 28, 28] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from qkeras import *\n",
    "\n",
    "kwargs = dict(input_quantizer=\"ste_sign\",\n",
    "              kernel_quantizer=\"ste_sign\",\n",
    "              kernel_constraint=\"weight_clip\",\n",
    "              use_bias=False)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    lq.layers.QConv2D(128, 3,\n",
    "                          kernel_quantizer=\"ste_sign\",\n",
    "                          kernel_constraint=\"weight_clip\",\n",
    "                          use_bias=False,\n",
    "                          input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
    "\n",
    "    lq.layers.QConv2D(128, 3, padding=\"same\", **kwargs),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
    "\n",
    "    lq.layers.QConv2D(256, 3, padding=\"same\", **kwargs),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
    "\n",
    "    lq.layers.QConv2D(256, 3, padding=\"same\", **kwargs),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
    "\n",
    "    lq.layers.QConv2D(512, 3, padding=\"same\", **kwargs),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
    "\n",
    "    lq.layers.QConv2D(512, 3, padding=\"same\", **kwargs),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    lq.layers.QDense(1024, **kwargs),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
    "\n",
    "    lq.layers.QDense(1024, **kwargs),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
    "\n",
    "    lq.layers.QDense(10, **kwargs),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
    "    tf.keras.layers.Activation(\"binary_tanh\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b744cdf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'binary_ops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningRateScheduler\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m np_utils\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbinary_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binary_tanh \u001b[38;5;28;01mas\u001b[39;00m binary_tanh_op\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbinary_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryDense\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDropoutNoScale\u001b[39;00m(Dropout):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'binary_ops'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3886f979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "487/487 [==============================] - 2s 1ms/step - loss: 1.2812 - accuracy: 0.5356 - val_loss: 1.0623 - val_accuracy: 0.6327\n",
      "Epoch 2/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 1.0285 - accuracy: 0.6383 - val_loss: 1.0107 - val_accuracy: 0.6539\n",
      "Epoch 3/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.9946 - accuracy: 0.6581 - val_loss: 1.0029 - val_accuracy: 0.6553\n",
      "Epoch 4/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.9680 - accuracy: 0.6716 - val_loss: 0.9525 - val_accuracy: 0.6845\n",
      "Epoch 5/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.9416 - accuracy: 0.6825 - val_loss: 0.9388 - val_accuracy: 0.6861\n",
      "Epoch 6/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.9184 - accuracy: 0.6928 - val_loss: 0.9405 - val_accuracy: 0.6772\n",
      "Epoch 7/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8993 - accuracy: 0.7000 - val_loss: 0.9016 - val_accuracy: 0.7031\n",
      "Epoch 8/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8864 - accuracy: 0.7041 - val_loss: 0.8874 - val_accuracy: 0.7063\n",
      "Epoch 9/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8758 - accuracy: 0.7063 - val_loss: 0.9208 - val_accuracy: 0.6883\n",
      "Epoch 10/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8650 - accuracy: 0.7096 - val_loss: 0.8658 - val_accuracy: 0.7099\n",
      "Epoch 11/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8610 - accuracy: 0.7099 - val_loss: 0.8520 - val_accuracy: 0.7136\n",
      "Epoch 12/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8498 - accuracy: 0.7127 - val_loss: 0.8676 - val_accuracy: 0.7068\n",
      "Epoch 13/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8467 - accuracy: 0.7131 - val_loss: 0.8371 - val_accuracy: 0.7160\n",
      "Epoch 14/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8398 - accuracy: 0.7143 - val_loss: 0.8661 - val_accuracy: 0.7104\n",
      "Epoch 15/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8397 - accuracy: 0.7139 - val_loss: 0.8293 - val_accuracy: 0.7186\n",
      "Epoch 16/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8316 - accuracy: 0.7165 - val_loss: 0.8320 - val_accuracy: 0.7180\n",
      "Epoch 17/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8320 - accuracy: 0.7162 - val_loss: 0.8323 - val_accuracy: 0.7186\n",
      "Epoch 18/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8303 - accuracy: 0.7166 - val_loss: 0.8371 - val_accuracy: 0.7161\n",
      "Epoch 19/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8263 - accuracy: 0.7179 - val_loss: 0.8305 - val_accuracy: 0.7181\n",
      "Epoch 20/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8245 - accuracy: 0.7181 - val_loss: 0.8257 - val_accuracy: 0.7214\n",
      "Epoch 21/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8219 - accuracy: 0.7187 - val_loss: 0.8209 - val_accuracy: 0.7205\n",
      "Epoch 22/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8211 - accuracy: 0.7191 - val_loss: 0.8177 - val_accuracy: 0.7205\n",
      "Epoch 23/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8187 - accuracy: 0.7200 - val_loss: 0.8292 - val_accuracy: 0.7173\n",
      "Epoch 24/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8180 - accuracy: 0.7203 - val_loss: 0.8179 - val_accuracy: 0.7216\n",
      "Epoch 25/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8154 - accuracy: 0.7206 - val_loss: 0.8569 - val_accuracy: 0.7089\n",
      "Epoch 26/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8140 - accuracy: 0.7212 - val_loss: 0.8173 - val_accuracy: 0.7203\n",
      "Epoch 27/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8126 - accuracy: 0.7216 - val_loss: 0.8095 - val_accuracy: 0.7231\n",
      "Epoch 28/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8126 - accuracy: 0.7214 - val_loss: 0.8083 - val_accuracy: 0.7239\n",
      "Epoch 29/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8116 - accuracy: 0.7216 - val_loss: 0.8092 - val_accuracy: 0.7229\n",
      "Epoch 30/30\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 0.8131 - accuracy: 0.7215 - val_loss: 0.8458 - val_accuracy: 0.7133\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "#     callbacks = all_callbacks(stop_patience = 1000,\n",
    "#                               lr_factor = 0.5,\n",
    "#                               lr_patience = 10,\n",
    "#                               lr_epsilon = 0.000001,\n",
    "#                               lr_cooldown = 2,\n",
    "#                               lr_minimum = 0.0000001,\n",
    "#                               outputDir = 'model_1')\n",
    "    model.fit(X_train_val, y_train_val, batch_size=1024, epochs=30, validation_split=0.25, shuffle=True)\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    model = load_model('model_1/KERAS_check_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdbe2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: Dense\n",
      "  -> Activation (linear), layer name: fc1\n",
      "Layer name: relu1, layer type: Activation\n",
      "Layer name: fc2, layer type: Dense\n",
      "  -> Activation (linear), layer name: fc2\n",
      "Layer name: relu2, layer type: Activation\n",
      "Layer name: fc3, layer type: Dense\n",
      "  -> Activation (linear), layer name: fc3\n",
      "Layer name: relu3, layer type: Activation\n",
      "Layer name: output, layer type: Dense\n",
      "  -> Activation (linear), layer name: output\n",
      "Layer name: softmax, layer type: Activation\n",
      "-----------------------------------\n",
      "Configuration\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 64]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: fc2, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Creating HLS model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chmoser/miniconda3/envs/tf/lib/python3.9/site-packages/hls4ml/converters/__init__.py:16: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "# plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model_1/hls4ml_prj',\n",
    "                                                       part='xc7a100t_ftg256.bsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a00fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()\n",
    "X_test = np.ascontiguousarray(X_test)\n",
    "y_hls = hls_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b83dee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5188/5188 [==============================] - 2s 351us/step\n",
      "Accuracy: 0.7117349397590361\n",
      "Keras  Accuracy: 0.7117349397590361\n",
      "hls4ml Accuracy: 0.20940361445783132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f821caa6220>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_keras = model.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "plt.figure(figsize=(9,9))\n",
    "# _ = plotting.makeRoc(y_test, y_keras, le.classes_)\n",
    "\n",
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "print(\"hls4ml Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "# _ = plotting.makeRoc(y_test, y_keras, le.classes_)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "# _ = plotting.makeRoc(y_test, y_hls, le.classes_, linestyle='--')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['keras', 'hls4ml'],\n",
    "            loc='lower right', frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8865b98",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Vivado HLS installation not found. Make sure \"vivado_hls\" is on PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhls_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/hls4ml/model/hls_model.py:722\u001b[0m, in \u001b[0;36mHLSModel.build\u001b[0;34m(self, reset, csim, synth, cosim, validation, export, vsynth)\u001b[0m\n\u001b[1;32m    720\u001b[0m     found \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommand -v vivado_hls > /dev/null\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m found \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 722\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVivado HLS installation not found. Make sure \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvivado_hls\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on PATH.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntel\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Vivado HLS installation not found. Make sure \"vivado_hls\" is on PATH."
     ]
    }
   ],
   "source": [
    "hls_model.build(csim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "576998e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "libdl.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhls_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/hls4ml/model/hls_model.py:539\u001b[0m, in \u001b[0;36mHLSModel.compile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_top_function_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinux\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 539\u001b[0m         dlclose_func \u001b[38;5;241m=\u001b[39m \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlibdl.so\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdlclose\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDarwin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    541\u001b[0m         dlclose_func \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibc.dylib\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdlclose\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/ctypes/__init__.py:382\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: libdl.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7087bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757abbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9e094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
